FROM apache/spark:3.5.0

# Switch to root to install Python
USER root

# Install dependencies and build Python 3.11 from source
RUN apt-get update && \
    apt-get install -y \
    wget \
    build-essential \
    libssl-dev \
    zlib1g-dev \
    libncurses5-dev \
    libncursesw5-dev \
    libreadline-dev \
    libsqlite3-dev \
    libgdbm-dev \
    libdb5.3-dev \
    libbz2-dev \
    libexpat1-dev \
    liblzma-dev \
    libffi-dev \
    uuid-dev && \
    # Download and build Python 3.11
    cd /tmp && \
    wget https://www.python.org/ftp/python/3.11.9/Python-3.11.9.tgz && \
    tar -xf Python-3.11.9.tgz && \
    cd Python-3.11.9 && \
    ./configure --enable-optimizations --with-ensurepip=install && \
    make -j $(nproc) && \
    make altinstall && \
    # Set Python 3.11 as default
    update-alternatives --install /usr/bin/python3 python3 /usr/local/bin/python3.11 1 && \
    update-alternatives --set python3 /usr/local/bin/python3.11 && \
    # Create symlink for pip
    ln -sf /usr/local/bin/pip3.11 /usr/local/bin/pip3 && \
    # Clean up
    cd / && \
    rm -rf /tmp/Python-3.11.9* && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Verify Python version
RUN python3 --version && pip3 --version

# Switch to spark user for JAR downloads
USER spark

# Download additional JARs directly into /opt/spark/jars
RUN cd /opt/spark/jars && \
    wget -q https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar && \
    wget -q https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.262/aws-java-sdk-bundle-1.12.262.jar && \
    wget -q https://jdbc.postgresql.org/download/postgresql-42.5.4.jar && \
    wget -q https://repo1.maven.org/maven2/io/delta/delta-spark_2.13/3.2.1/delta-spark_2.13-3.2.1.jar && \
    echo "Additional JARs installed"

# Keep the original entrypoint
# ENTRYPOINT is inherited from base image

USER spark